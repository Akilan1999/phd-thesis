
@article{navarro_practical_nodate,
	title = {Practical, transparent operating system support for superpages},
	abstract = {Most general-purpose processors provide support for memory pages of large sizes, called superpages. Superpages enable each entry in the translation lookaside buffer ({TLB}) to map a large physical memory region into a virtual address space. This dramatically increases {TLB} coverage, reduces {TLB} misses, and promises performance improvements for many applications. However, supporting superpages poses several challenges to the operating system, in terms of superpage allocation and promotion tradeoffs, fragmentation control, etc. We analyze these issues, and propose the design of an effective superpage management system. We implement it in {FreeBSD} on the Alpha {CPU}, and evaluate it on real workloads and benchmarks. We obtain substantial performance beneﬁts, often exceeding 30\%; these beneﬁts are sustained even under stressful workload scenarios.},
	author = {Navarro, Juan},
	langid = {english},
	file = {Navarro - Practical, transparent operating system support fo.pdf:/Users/akilan/Zotero/storage/9RBYAPGM/Navarro - Practical, transparent operating system support fo.pdf:application/pdf},
}

@inproceedings{panwar_hawkeye_2019,
	location = {Providence {RI} {USA}},
	title = {{HawkEye}: Efficient Fine-grained {OS} Support for Huge Pages},
	isbn = {978-1-4503-6240-5},
	url = {https://dl.acm.org/doi/10.1145/3297858.3304064},
	doi = {10.1145/3297858.3304064},
	shorttitle = {{HawkEye}},
	eventtitle = {{ASPLOS} '19: Architectural Support for Programming Languages and Operating Systems},
	pages = {347--360},
	booktitle = {Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems},
	publisher = {{ACM}},
	author = {Panwar, Ashish and Bansal, Sorav and Gopinath, K.},
	urldate = {2024-05-27},
	date = {2019-04-04},
	langid = {english},
	file = {Full Text PDF:/Users/akilan/Zotero/storage/VQLCKYCA/Panwar et al. - 2019 - HawkEye Efficient Fine-grained OS Support for Hug.pdf:application/pdf},
}

@article{basu_efficient_nodate,
	title = {Efficient Virtual Memory for Big Memory Servers},
	abstract = {Our analysis shows that many “big-memory” server workloads, such as databases, in-memory caches, and graph analytics, pay a high cost for page-based virtual memory. They consume as much as 10\% of execution cycles on {TLB} misses, even using large pages. On the other hand, we find that these workloads use read-write permission on most pages, are provisioned not to swap, and rarely benefit from the full flexibility of page-based virtual memory.},
	author = {Basu, Arkaprava and Gandhi, Jayneel and Chang, Jichuan and Hill, Mark D and Swift, Michael M},
	langid = {english},
	file = {Basu et al. - Efficient Virtual Memory for Big Memory Servers.pdf:/Users/akilan/Zotero/storage/JJ5M79Q9/Basu et al. - Efficient Virtual Memory for Big Memory Servers.pdf:application/pdf},
}

@inproceedings{karakostas_redundant_2015,
	location = {Portland Oregon},
	title = {Redundant memory mappings for fast access to large memories},
	isbn = {978-1-4503-3402-0},
	url = {https://dl.acm.org/doi/10.1145/2749469.2749471},
	doi = {10.1145/2749469.2749471},
	abstract = {Page-based virtual memory improves programmer productivity, security, and memory utilization, but incurs performance overheads due to costly page table walks after {TLB} misses. This overhead can reach 50\% for modern workloads that access increasingly vast memory with stagnating {TLB} sizes. To reduce the overhead of virtual memory, this paper proposes Redundant Memory Mappings ({RMM}), which leverage ranges of pages and provides an efﬁcient, alternative representation of many virtual-to-physical mappings. We deﬁne a range be a subset of process’s pages that are virtually and physically contiguous. {RMM} translates each range with a single range table entry, enabling a modest number of entries to translate most of the process’s address space. {RMM} operates in parallel with standard paging and uses a software range table and hardware range {TLB} with arbitrarily large reach. We modify the operating system to automatically detect ranges and to increase their likelihood with eager page allocation. {RMM} is thus transparent to applications. We prototype {RMM} software in Linux and emulate the hardware. {RMM} performs substantially better than paging alone and huge pages, and improves a wider variety of workloads than direct segments (one range per program), reducing the overhead of virtual memory to less than 1\% on average.},
	eventtitle = {{ISCA} '15: The 42nd Annual International Symposium on Computer Architecture},
	pages = {66--78},
	booktitle = {Proceedings of the 42nd Annual International Symposium on Computer Architecture},
	publisher = {{ACM}},
	author = {Karakostas, Vasileios and Gandhi, Jayneel and Ayar, Furkan and Cristal, Adrián and Hill, Mark D. and {McKinley}, Kathryn S. and Nemirovsky, Mario and Swift, Michael M. and Ünsal, Osman},
	urldate = {2024-05-27},
	date = {2015-06-13},
	langid = {english},
	file = {Karakostas et al. - 2015 - Redundant memory mappings for fast access to large.pdf:/Users/akilan/Zotero/storage/8JECES24/Karakostas et al. - 2015 - Redundant memory mappings for fast access to large.pdf:application/pdf},
}

@article{chen_flexpointer_2023,
	title = {{FlexPointer}: Fast Address Translation Based on Range {TLB} and Tagged Pointers},
	volume = {20},
	issn = {1544-3566, 1544-3973},
	url = {https://dl.acm.org/doi/10.1145/3579854},
	doi = {10.1145/3579854},
	shorttitle = {{FlexPointer}},
	abstract = {Page-based virtual memory relies on {TLBs} to accelerate the address translation. Nowadays, the gap between application workloads and the capacity of {TLB} continues to grow, bringing many costly {TLB} misses and making the {TLB} a performance bottleneck. Previous studies seek to narrow the gap by exploiting the contiguity of physical pages. One promising solution is to group pages that are both virtually and physically contiguous into a memory range. Recording range translations can greatly increase the {TLB} reach, but ranges are also hard to index because they have arbitrary bounds. The processor has to compare against all the boundaries to determine which range an address falls in, which restricts the usage of memory ranges.
            In this article, we propose a tagged-pointer-based scheme, {FlexPointer}, to solve the range indexing problem. The core insight of {FlexPointer} is that large memory objects are rare, so we can create memory ranges based on such objects and assign each of them a unique {ID}. With the range {ID} integrated into pointers, we can index the range {TLB} with {IDs} and greatly simplify its structure. Moreover, because the {ID} is stored in the unused bits of a pointer and is not manipulated by the address generation, we can shift the range lookup to an earlier stage, working in parallel with the address generation. According to our trace-based simulation results, {FlexPointer} can reduce nearly all the L1 {TLB} misses, and page walks for a variety of memory-intensive workloads. Compared with a 4K-page baseline system, {FlexPointer} shows a 14\% performance improvement on average and up to 2.8x speedup in the best case. For other workloads, {FlexPointer} shows no performance degradation.},
	pages = {1--24},
	number = {2},
	journaltitle = {{ACM} Transactions on Architecture and Code Optimization},
	shortjournal = {{ACM} Trans. Archit. Code Optim.},
	author = {Chen, Dongwei and Tong, Dong and Yang, Chun and Yi, Jiangfang and Cheng, Xu},
	urldate = {2024-05-27},
	date = {2023-06-30},
	langid = {english},
	file = {Full Text PDF:/Users/akilan/Zotero/storage/L9XGZDFK/Chen et al. - 2023 - FlexPointer Fast Address Translation Based on Ran.pdf:application/pdf},
}

@article{woodruff_cheri_2019,
	title = {{CHERI} Concentrate: Practical Compressed Capabilities},
	volume = {68},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {0018-9340, 1557-9956, 2326-3814},
	url = {https://ieeexplore.ieee.org/document/8703061/},
	doi = {10.1109/TC.2019.2914037},
	shorttitle = {{CHERI} Concentrate},
	abstract = {We present {CHERI} Concentrate, a new fat-pointer compression scheme applied to {CHERI}, the most developed capability-pointer system at present. Capability fat pointers are a primary candidate to enforce ﬁne-grained and non-bypassable security properties in future computer systems, although increased pointer size can severely affect performance. Thus, several proposals for capability compression have been suggested elsewhere that do not support legacy instruction sets, ignore features critical to the existing software base, and also introduce design inefﬁciencies to {RISC}-style processor pipelines. {CHERI} Concentrate improves on the state-of-the-art region-encoding efﬁciency, solves important pipeline problems, and eases semantic restrictions of compressed encoding, allowing it to protect a full legacy software stack. We present the ﬁrst quantitative analysis of compiled capability code, which we use to guide the design of the encoding format. We analyze and extend logic from the open-source {CHERI} prototype processor design on {FPGA} to demonstrate encoding efﬁciency, minimize delay of pointer arithmetic, and eliminate additional load-to-use delay. To verify correctness of our proposed high-performance logic, we present a {HOL}4 machine-checked proof of the decode and pointer-modify operations. Finally, we measure a 50\% to 75\% reduction in L2 misses for many compiled C-language benchmarks running under a commodity operating system using compressed 128-bit and 64-bit formats, demonstrating both compatibility with and increased performance over the uncompressed, 256-bit format.},
	pages = {1455--1469},
	number = {10},
	journaltitle = {{IEEE} Transactions on Computers},
	shortjournal = {{IEEE} Trans. Comput.},
	author = {Woodruff, Jonathan and Joannou, Alexandre and Xia, Hongyan and Fox, Anthony and Norton, Robert M. and Chisnall, David and Davis, Brooks and Gudka, Khilan and Filardo, Nathaniel W. and Markettos, A. Theodore and Roe, Michael and Neumann, Peter G. and Watson, Robert N. M. and Moore, Simon W.},
	urldate = {2024-05-27},
	date = {2019-10-01},
	langid = {english},
	file = {Woodruff et al. - 2019 - CHERI Concentrate Practical Compressed Capabiliti.pdf:/Users/akilan/Zotero/storage/3SZUIWQ5/Woodruff et al. - 2019 - CHERI Concentrate Practical Compressed Capabiliti.pdf:application/pdf},
}

@online{noauthor_capability-based_nodate,
	title = {Capability-Based Computer Systems},
	url = {https://homes.cs.washington.edu/~levy/capabook/},
	urldate = {2024-06-07},
	file = {Capability-Based Computer Systems:/Users/akilan/Zotero/storage/IAAG6ZF3/capabook.html:text/html},
}

@article{woodruff_cheri_2014,
	title = {The {CHERI} capability model: revisiting {RISC} in an age of risk},
	volume = {42},
	issn = {0163-5964},
	url = {https://doi.org/10.1145/2678373.2665740},
	doi = {10.1145/2678373.2665740},
	shorttitle = {The {CHERI} capability model},
	abstract = {Motivated by contemporary security challenges, we reevaluate and refine capability-based addressing for the {RISC} era. We present {CHERI}, a hybrid capability model that extends the 64-bit {MIPS} {ISA} with byte-granularity memory protection. We demonstrate that {CHERI} enables language memory model enforcement and fault isolation in hardware rather than software, and that the {CHERI} mechanisms are easily adopted by existing programs for efficient in-program memory safety. In contrast to past capability models, {CHERI} complements, rather than replaces, the ubiquitous page-based protection mechanism, providing a migration path towards deconflating data-structure protection and {OS} memory management. Furthermore, {CHERI} adheres to a strict {RISC} philosophy: it maintains a load-store architecture and requires only singlecycle instructions, and supplies protection primitives to the compiler, language runtime, and operating system. We demonstrate a mature {FPGA} implementation that runs the {FreeBSD} operating system with a full range of software and an open-source application suite compiled with an extended {LLVM} to use {CHERI} memory protection. A limit study compares published memory safety mechanisms in terms of instruction count and memory overheads. The study illustrates that {CHERI} is performance-competitive even while providing assurance and greater flexibility with simpler hardware},
	pages = {457--468},
	number = {3},
	journaltitle = {{ACM} {SIGARCH} Computer Architecture News},
	shortjournal = {{SIGARCH} Comput. Archit. News},
	author = {Woodruff, Jonathan and Watson, Robert N.M. and Chisnall, David and Moore, Simon W. and Anderson, Jonathan and Davis, Brooks and Laurie, Ben and Neumann, Peter G. and Norton, Robert and Roe, Michael},
	urldate = {2024-06-07},
	date = {2014-06-14},
}

@article{miller_towards_nodate,
	title = {Towards a Uniﬁed Approach to Access Control and Concurrency Control},
	author = {Miller, Mark Samuel},
	langid = {english},
	file = {Miller - Towards a Uniﬁed Approach to Access Control and Co.pdf:/Users/akilan/Zotero/storage/7METVAKG/Miller - Towards a Uniﬁed Approach to Access Control and Co.pdf:application/pdf},
}

@inproceedings{curtsinger_coz_2015,
	title = {Coz: Finding Code that Counts with Causal Profiling},
	url = {http://arxiv.org/abs/1608.03676},
	doi = {10.1145/2815400.2815409},
	shorttitle = {Coz},
	abstract = {Improving performance is a central concern for software developers. To locate optimization opportunities, developers rely on software proﬁlers. However, these proﬁlers only report where programs spent their time: optimizing that code may have no impact on performance. Past proﬁlers thus both waste developer time and make it difﬁcult for them to uncover signiﬁcant optimization opportunities.},
	pages = {184--197},
	booktitle = {Proceedings of the 25th Symposium on Operating Systems Principles},
	author = {Curtsinger, Charlie and Berger, Emery D.},
	urldate = {2024-06-07},
	date = {2015-10-04},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1608.03676 [cs]},
	keywords = {C.4, Computer Science - Performance, D.4.8},
	file = {Curtsinger and Berger - 2015 - Coz Finding Code that Counts with Causal Profilin.pdf:/Users/akilan/Zotero/storage/QTFQXVHE/Curtsinger and Berger - 2015 - Coz Finding Code that Counts with Causal Profilin.pdf:application/pdf},
}

@online{noauthor_benchmark_nodate,
	title = {Benchmark {ABI} - {CheriBSD} 23.11 new features tutorial},
	url = {https://www.cheribsd.org/tutorial/23.11/benchmark/index.html},
	urldate = {2024-06-07},
	file = {Benchmark ABI - CheriBSD 23.11 new features tutorial:/Users/akilan/Zotero/storage/9BDKUW28/index.html:text/html},
}

@inproceedings{zhu_research_2018,
	location = {Taipei, Taiwan},
	title = {Research and Implementation of High Performance Traffic Processing Based on Intel {DPDK}},
	isbn = {978-1-5386-9403-9},
	url = {https://ieeexplore.ieee.org/document/8701793/},
	doi = {10.1109/PAAP.2018.00018},
	eventtitle = {2018 9th International Symposium on Parallel Architectures, Algorithms and Programming ({PAAP})},
	pages = {62--68},
	booktitle = {2018 9th International Symposium on Parallel Architectures, Algorithms and Programming ({PAAP})},
	publisher = {{IEEE}},
	author = {Zhu, Wenjun and Li, Peng and Luo, Baozhou and Xu, He and Zhang, Yujie},
	urldate = {2024-06-07},
	date = {2018-12},
}

@article{bi_dpdk-based_2016,
	title = {{DPDK}-based Improvement of Packet Forwarding},
	volume = {7},
	rights = {© Owned by the authors, published by {EDP} Sciences, 2016},
	issn = {2271-2097},
	url = {https://www.itm-conferences.org/articles/itmconf/abs/2016/02/itmconf_ita2016_01009/itmconf_ita2016_01009.html},
	doi = {10.1051/itmconf/20160701009},
	abstract = {Reel-time processing of packets occupies a significant position in the field of computer network security. With theexplosive growth of the backbone link rate,which is consistent with Gilder's law, many bottlenecks of server performance leave the real-time data stream unprocessed.Thus, we proposedto take use of {DPDK}(Data Plan Development Kit) framework to achieve an intelligent {NIC} packet forwarding system. During this research, we deeply analysis the forwarding process of packet in {DPDK} and improve its {DMA} mode.According to the results of experiment, the system greatly enhanced the performance of packet forwarding,and the throughput of forwarding 64-byet or random-length packets by 20Gbit {NIC} reaches13.3Gbps and 18.7Gbps(dual ports forwarding).},
	pages = {01009},
	journaltitle = {{ITM} Web of Conferences},
	shortjournal = {{ITM} Web Conf.},
	author = {Bi, Hao and Wang, Zhao-Hun},
	urldate = {2024-06-07},
	date = {2016},
	langid = {english},
	note = {Publisher: {EDP} Sciences},
	file = {Full Text PDF:/Users/akilan/Zotero/storage/LEVMJ983/Bi and Wang - 2016 - DPDK-based Improvement of Packet Forwarding.pdf:application/pdf},
}

@online{noauthor_arm_nodate,
	title = {Arm Architecture Reference Manual for A-profile architecture},
	url = {https://developer.arm.com/documentation/ddi0487/latest},
	urldate = {2024-06-08},
	file = {Arm Architecture Reference Manual for A-profile architecture:/Users/akilan/Zotero/storage/72DMZYM2/latest.html:text/html},
}

@online{noauthor_getting_nodate,
	title = {Getting Started with {CheriBSD} 23.11 - Getting Started with {CheriBSD} 23.11},
	url = {https://ctsrd-cheri.github.io/cheribsd-getting-started/cover/index.html},
	urldate = {2024-06-08},
	file = {Getting Started with CheriBSD 23.11 - Getting Started with CheriBSD 23.11:/Users/akilan/Zotero/storage/4NSMMRDG/index.html:text/html},
}
