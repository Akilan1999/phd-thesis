]%!TEX root = ../thesis.tex
%*******************************************************************************
%*********************************** Literature Review *****************************
%*******************************************************************************

\chapter{Literature Review}  %Title of the Literature Review

\ifpdf
    \graphicspath{{LiteratureReview/Figs/Raster/}{LiteratureReview/Figs/PDF/}{LiteratureReview/Figs/}}
\else
    \graphicspath{{LiteratureReview/Figs/Vector/}{LiteratureReview/Figs/}}
\fi

%********************************** %Introduction for literature review **************************************

The literature review is split into 3 sections. The first section talks about the papers surveyed 
for Unikernels and the 2nd section talks about papers surveyed for TAG based architectures and 
the third sections talks about the possible incentives of combining them both which helps 
answer the research questions stated (TODO: Add reference to research question section). 

\section[Unikernels]{Unikernels Survey}

\subsection{Implementations}

\subsubsection{Unikraft}
Unikraft is a uni-kernel implementation that claims to be 
a micro library OS. The major features of Unikraft is:
\begin{itemize}
  \item Single address space: Intended to target single applications.
  \item Fully modular system: All drivers and platform libraries can be easily removed.
  \item Single protection level: No kernel and user space seperation to avoid costly context switching.
  \item Static linking: Compiler features such as dead code elimination and link time optmization supported. 
  \item POSIX support: Support for legacy applications while still allowing for specialization. 
  \item Platform abstraction: The ability to run on different Hypervisors/VMs. 
\end{itemize}
To reach for the principal of modularity. Unikraft consists of 2 major componenents: 
\begin{itemize}
  \item Micro libraries: Micro-libraries are software components 
  which implement one of the core Unikraft APIs.
  \item Build system: he build system
  then compiles all of the micro-libraries, links them,
  and produces one binary per selected platform.
\end{itemize}
In terms of performance the following was evaluated: 
\begin{itemize}
  \item Resource Efficiency (Smaller is Better): Overall, the total VM boot time is dominated by the VMM,
  with Solo5 and Firecracker being the fastest (3ms), QEMU
  microVM at around 10ms and QEMU the slowest at around
  40ms.
  \item Filesystem Performance: Unikraft
  achieves lower read latency and lower write latency with
  different block sizes and are considerably better than ones
  from the Linux VM.
  \item Application Throughput: Unikraft is around 30\%-80\% faster than running the same app
  in a container, and 70\%-170\% faster than the same app running 
  in a Linux VM. Surprisingly, Unikraft is also 10\%-60\%
  faster than Native Linux in both cases.
  \item Performance of Automatically Ported Apps: The results
  show that the automatically ported app is only 1.5\% slower
  than the manually ported version, and even slightly faster
  than Linux baremetal.
\end{itemize}

\subsubsection{OSv}
OSv is an unikernel that runs existing Linux cloud applications on various hypervisors 
and machine architectures. OSv runs on 64-bit x86 and
ARM architectures and supports KVM/Qemu, VMware, Xen and VirtualBox 
hypervisors.OSv demonstrates up to 25\% increase in throughput and 47\% 
decrease in latency. 
By using non-POSIX network APIs,
it can further improve performance and demonstrate a
290\% increase in Memcached throughput.
OSv is designed as a drop-in replacement for applications that use a
supported subset of the Linux application binary interface (ABI).
The following below is the design of OSv: 
\begin{itemize}
  \item Memory Management: OSv uses virtual memory like
  general purpose OSs.OSv supports demand paging and memory mapping
  via the mmap API.
  \item No Spinlocks: The mutex implementation is based on a lock-free design 
  by Gidenstam \& Papatriantafilou (add reference), which protects
  the mutexâ€™s internal data structures with atomic opera-
  tions in a lock-free fashion.
  \item Network Channels: OSv almost all packet processing is performed in an application thread. 
  Upon packet receipt, a simple classifier associates it with a channel, which is a single producer/single
  consumer queue for transferring packets to the application thread.
\end{itemize}

\subsubsection{HermitCore}
HermitCore is an Unikernel implementation designed for HPC. The kernel extends the
multi-kernel approach with the advantages of a unikernel.The focus of HermitCore is 
the mapping of the hardware to
the software structure rather than full support of the Linux
API.In a HermitCore system, each NUMA node runs its own HermitCore instance managing all its resources.
The aims for Hermit core are the following:
\begin{itemize}
  \item Reduction of OS noise.
  \item Predictable runtimes.
  \item Maintainability, extensibility, and flexibility.
  \item Abstraction of hardware details.
  \item Support for common HPC programming models (e. g.,
  OpenMP, MPI).
  \item Simple integration into existing software stacks of
  compute centers.
\end{itemize}
Benchmarks conducted:
\begin{itemize}
  \item Operating System Micro-Benchmarks.
  \item Hourglass Benchmark (For OS Noise).
  \item Inter-kernel Communication Benchmark.
  \item OpenMP Micro-Benchmarks.
\end{itemize}

\subsubsection{RKOS}
RKOS is an unikernel implemented in Rust which
offers safety guarantees comparable to implementations which depend on complex runtime
libraries while being capable of providing predictable application performance demanded
by real-time applications in a relatively simple implementation. 
Design decisions for RKOS are as follows:
\begin{itemize}
  \item Mutual trust between components allows a shared, uniform address space.
  \item Virtualized runtime environments have uniform hardware configuration.
\end{itemize}
Performance Evaluations conducted:
\begin{itemize}
  \item Run time memory footprint 
  \item Binary size 
\end{itemize}

\subsubsection{ClickOS}
ClickOS is an unikernel optimized for middleboxes that runs exclusively on
the Xen hypervisor with small virtual machine memory footprint overhead
(5 MB), fast boot times (under 30 milliseconds), and high performance
networking capabilities.ClickOS adds only a 45 microsecond delay per
packet. When compared to a general purpose Linux also running on Xen,
ClickOS network throughput is up to 1.5x times higher for MTU-sized packets
and as much as 13.6x times higher for minimum-sized packets. 

\subsubsection{NanoOS}
Nanos is a Unikernel implementation designed to run micro services on the 
Cloud it runs on top a Qemu Hypervisor. It has it's own Orchestrator 
written in Go called OPS. 
Nanos employs various forms of security measures found in other general purpose operating systems including ASLR and respects page protections 
that compilers produce.

ASLR:

\begin{itemize}
  \item Stack Randomization
  \item Heap Randomization
  \item Library Randomization
  \item Binary Randomization
\end{itemize}

Page Protections:

\begin{itemize}
  \item Stack Execution off by Default
  \item Heap Execution off by Default
  \item Null Page is Not Mapped
  \item Rodata no execute
  \item Text no write
\end{itemize}

\begin{itemize}
  \item SMEP
  \item UMIP
\end{itemize}

Performance Evaluations conducted:
\begin{itemize}
  \item Bootup Times.
  \item Requests per second.
\end{itemize}

\subsubsection{IncludeOS}
IncludeOS is a single tasking library operating system for 
cloud services which is written from scratch in C++. Key features include:
extremely small disk and memory footprint, efficient asynchronous I/O, 
OS-library where only what your service needs gets included.
In the test case the bootable disk image consisting
of a simple DNS server with OS included is shown
to require only 158 kb of disk space and to require
5-20\% less CPU-time.
The contribrutions of IncludeOS are:
\begin{itemize}
  \item Extreme resource efficiency and footprint.
  \item Efficient deployment process.
  \item Virtualization platform independence.
\end{itemize}
The proposed benefits of IncludeOS  in comparison to Linux Kernels are:
\begin{itemize}
  \item Extremely small disk and memory footprint.
  \item No host or software dependencies, other than
  virtual x86 hardware, and standard virtio for
  networking
  \item No system call overhead (The OS and the
  services are in the same binary, and the system calls
  are simple function calls(i.e without passing any
  memory protection barriers)).
  \item Reduced number of VM exits by keeping the
  number of protected instructions very low.
\end{itemize}

Performance Evaluations conducted:
\begin{itemize}
  \item Bootup times 
  \item Memory performance (i.e The Stream Benchmark)
\end{itemize}











\section[TAG based architecture survey]{TAG based architecture survey}   
The following was a survey conducted on exisisting TAG based implementations and the 
recent survey based on TAG based architectures \cite{acmTAGSurvey} published
in 2022 was a good staring point to understand about various implementations of TAG
based archtectures with the high level metrits and limitations. The following section 
provides our own version of the Survey to help decide the best implementations 
to answer the research questions (//TODO reference research questions chapter).

Before deep diving into TAG based architecture implementations it is important to 
answer what is a TAG based architecture ? and the high level of various 
categories of various TAG based architectures.

Tagged architectures are a prominent class of hardware security primitives that augment data and code words
with tags. The tags, which function as the security metadata
about memory, are created before the program is loaded. 
Then, at runtime, the hardware enforces security policies on the tags to provide safety guarantees. 
The advantage being tags automate the secure and efficient management of security metadata. 

Tags policies as designed to address mostly:
\begin{itemize}
  \item Type and memory corruption
  \item Integer overflows
  \item Thread safety
  \item Buffer overflows
\end{itemize}

TAG policies can be categorised into 5 main categories which is:
\begin{itemize}
  \item Information-low control (IFC) policies
  \item Dynamic information-low tracking (DIFT) policies
  \item Capability models
  \item Programmable architectures
\end{itemize}
 
According to the TAG based architecture survey \cite{acmTAGSurvey} there are 37 published
efforts on TAG based architectures over the past decade and 20 published efforts preceding that. 

\subsection{Timder V \cite{weiser_timber-v_2019}}
 It is a tagged memory architecture for flexible and efficient isolation of code and data on 
 small embedded systems. The TAG isolation is augmented with a memory protection unit to isolate 
 induvidual processes. Timber V is compatible with exsisting code. The contributions of the paper 
 are: 
 \begin{itemize}
  \item Efficient tagged memory architecture for isolated execution on low-end processors. 
  \item Concept introducted called stack interleaving that allows efficient and dynamic memory management. 
  \item Lightweight shared memory between enclaves. 
  \item Efficient shared MPU (i.e Memory Protection Unit) design. 
 \end{itemize}
 

%~\ref{weiser_timber-v_2019}
%           FORMAT     
% TODO 
%  - Get bibtex file for references for TAG based architecture 
%  - Start paragraph 
%  - Benchmarks and test performaned  
	
\subsection{ARM MTE \cite{ARMMTE}}
The ARMv8.5-Memory Tagging Extension (MTE) aims to increase the memory safety written for 
unsafe languages without requiring source code changes and in certain cases without 
recompilation. It generally foicuses on the bounds checking use case, Though it 
provides limited tags which means it can only provide probablilistic overflow detection. 
It is one of the latest commercial incarnations of memory-safety-focused tagged architectures.   

\subsection{D-RI5CY \cite{D-RISCY}}
It provides a design a design and implementation of a hardware dynamic information flow 
tracking (DIFT) architecture for RISC-V processor cores. The paper presents a low 
overhead implementation of DIFT that is specialized for low-end embedded systems
for IOT applications. The following are high level contributions:
\begin{itemize}
  \item Design f D-RI5CY, A DIFT-protected implementation of the RI5CY processor core. 
        The paper implements the modification of the DIFT TAG propogation and TAG checking
        mechanism in a way that is transparent to the execution of the regular instructions. 
  \item Concept introducted called stack interleaving that allows efficient and dynamic memory management.
  \item Lightweight shared memory between enclaves.
  \item Efficient shared MPU (i.e Memory Protection Unit) design.
\end{itemize}


%\subsection{TMDFI}


\subsection{HyperFlow \cite{HyperFlow}} 
It is a design and security implementation that offers security assurance because it is implemented 
using a security-typed hardware description language. It allows complex information flow policies to 
be configured at run time. The paper introduces ChiselFlow, a new secure hardware description language. 
The contribution of the paper includes: 
\begin{itemize}
  \item Processor architecture and implementation designed for timing-safe information flow security. 
  \item Complere RISC-V intruction set extended with intructions for information flow control. 
  \item Verified at design time with a hardware description language. 
  \item Novel representations of lattices that can be implemented in hardware efficiently. 
\end{itemize}
Hyperlow implements a nonmalleable IFC policy using tags.
To eliminate timing side channels, the processor tracks the tag of the currently executing code and lushes caches,
TLB, branch predictor, and other microarchitectural state on changes in the conidentiality or integrity tag of the
running code. The modifications to avoid timing side channels seem more extensive than those to add tags. The
authors report overheads in cycles per instruction of between 1\% and 69\%, largely due to padding the multiply
operation to the worst-case number of cycles.

\subsection{SDMP \cite{Sdmp}}
This paper focuses on designing metadata tag based stack-protection security policies for general purpose tagged
architecture. The policies specifically
exploit the natural locality of dynamic program call graphs to
achieve cacheability of the metadata rules that they require.
The simple Return Address Protection policy has a performance
overhead of 1.2\% but just protects return addresses.
The two richer policies present, Static Authorities and Depth Isola-
tion, provide object-level protection for all stack objects. When
enforcing memory safety, The Static Authorities policy has a
performance overhead of 5.7\% and the Depth Isolation policy
has a performance overhead of 4.5\%.
The contribution of the paper includes:
\begin{itemize}
  \item The formulation of a range of stack protection policies
within the SDMP model.
  \item Three optimizations for the stack policies: Lazy Tagging,
Lazy Clearing and Cache Line Tagging.
  \item The performance modeling results of the policies on
a standard benchmark set, including the impact of the
proposed optimizations.
\end{itemize}  

\subsection{Typed Architecture \cite{TypedArchitecture}}
This paper introduces Typed
Architectures, a high-efficiency, low-cost execution sub-
strate for dynamic scripting languages, where each data
variable retains high-level type information at an ISA level.
Typed Architectures calculate and check the dynamic type
of each variable implicitly in hardware, rather than explicitly
in software. Typed Architectures provide
hardware support for flexible yet efficient type tag extraction
and insertion, capturing common data layout patterns of tag-
value pairs. The evaluation using a fully synthesizable RISC-
V RTL design on FPGA shows that Typed Architectures
achieve mean speedups of 11.2\% and 9.9\% with
minimum speedups of 32.6\% and 43.5\% for two production-
grade scripting engines for JavaScript and Lua. 
The contribution of the paper includes:
\begin{itemize}
  \item ISA extension to efficiently manage
type tags in hardware, which can be flexibly applied to
multiple scripting languages and engines.
  \item Design and implement the Typed Architecture pipeline,
which effectively reduces the overhead of dynamic type
checking at low hardware cost.
  \item Prototype the proposed processor architecture using 
a fully synthesizable RTL model to execute two
production-grade scripting engines with large inputs on
FPGA (executing over 274 billion instructions in total)
and provide a more accurate estimate of area and power
using a TSMC 40nm standard cell library.
\end{itemize}

\subsection{Dover \cite{Dover}}
It is a secure processor that extends the conventional CPU with
a Policy EXecution co-processor (PEX). PEX maintains metadata 
of every word assesible by the application processor. PEX 
enforces software-defined policies
at the granularity of each instruction executed by the AP(i.e application process)
CPU. Hardware interlocks enforce strict separation between code and data 
for user-land and policy-related. The Dover system has 
a dover specialized kernel and modifications to the GCC toolchain 
which can implement a wide range security and safety policies on 
top exsisting C based applications. 
%// TODO ADD DIAGRAM. 

%\subsection{Shakti-T}

%\subsection{HDFI}

%\subsection{lowRISC}

%\subsection{Taxi}

%\subsection{Pump}

\subsection{CHERI \cite{CHERI}}
CHERI (Capability Hardware Enhanced RISC Instructions) extends conventional processor
Instruction-Set Architectures (ISAs) with architectural capabilities to enable fine-grained
memory protection and highly scalable software compartmentalization. CHERI is a hybrid 
capability architecture that can combine capabilities with conventional MMU(i.e Memory Management
 Unit) based systems. The contribution of the following project include: 
\begin{itemize}
  \item ISA changes to introduce architecture capabilities.
  \item New microarchitecture proving that capabilities can be implemented efficiently 
        in hardware. Support for efficient tagged memory to protect capabilities and
        compress capabilities to reduce memory overhead.   
  \item Newly designed software construction model for that uses capability to provide
        fine grain memory protection and scalable software compartmentalization.  
  \item Langauge and Compiler extension to use capabilities for C and C++.
  \item OS extensions to use (and support application use of) fine-grained memory protection
        (spatial, referential, and (non-stack) temporal memory safety) and abstraction extensions
        to support scalable software compartmentalization. 
\end{itemize}
	
%\subsection{SPARC M7/M8 SSM}

%\subsection{Low-Fat Pointers}

%\subsection{SAFE}

%\subsection{DataSafe}

%\subsection{Harmoni}

%\subsection{Shioya, et al.}

%\subsection{SIFT}

%\subsection{FlexCore}

%\subsection{Execution Leases}

%\subsection{GLIFT}

%\subsection{TIARA}

%\subsection{DIFT Coprocessor}

%\subsection{HardBound}

%\subsection{Loki}

%\subsection{FLexiTaint}

%\subsection{SECTAG}

%\subsection{Raksha}

%\subsection{SecureBit}

%\subsection{Minos}

%\subsection{DIFT}

%\subsection{RIFLE}

%\subsection{AEGIS}

%\subsection{Mondriaan}

%\subsection{Aries}

%\subsection{XOM}

%\subsection{M-Machine}

%\subsection{KCM}

%\subsection{SPUR}

%\subsection{Lisp Machine}

%\subsection{HEP}

%\subsection{Burroughs}






































